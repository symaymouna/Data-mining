{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sklearn\n",
    "import unidecode\n",
    "from stop_words import get_stop_words\n",
    "import string\n",
    "#fonction de pre-traitement dees données\n",
    "def pretraitement(file):\n",
    "    data = {}\n",
    "    X = []\n",
    "    y = []\n",
    "    with open(file ,'r', encoding='ISO8859-1') as f:\n",
    "       for line in f:\n",
    "\n",
    "           tab = []\n",
    "           y.append(line[line.find(\">\")-1])\n",
    "           x = (line[line.find(\">\")+2:])\n",
    "           x = x.lower()\n",
    "           x = x.replace(\"'\",\" \")\n",
    "           x = x.replace(\"\\n\",\"\")\n",
    "           x = x.translate(str.maketrans('', '', string.punctuation))\n",
    "           x_split = x.split(' ')\n",
    "           x = ''\n",
    "           for i in range(len(x_split)):\n",
    "            if x_split[i] in get_stop_words('fr') or len(x_split[i]) == 1:\n",
    "                x_split[i] = ' '\n",
    "            x = x + \" \" + x_split[i]\n",
    "\n",
    "           x = unidecode.unidecode(x)\n",
    "           X.append([x])\n",
    "    data['X'] = X\n",
    "    data['y'] = y\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation des données "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Pre-traitement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# données d'apprentissage \n",
    "train_file = 'CorpusM2-AFD/corpus.tache1.test'\n",
    "data_train = pretraitement(train_file)\n",
    "x_train = data_train['X']\n",
    "y_train = data_train['y']\n",
    "# données de test\n",
    "test_file = 'CorpusM2-AFD/corpus.tache1.learn'\n",
    "data_test = pretraitement(test_file)\n",
    "x_test = data_train['X']\n",
    "y_test = data_train['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2. Lemmatisation avec TreeTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/treetaggerwrapper.py:740: FutureWarning: Possible nested set at position 8\n",
      "  re.IGNORECASE | re.VERBOSE)\n",
      "/anaconda3/lib/python3.7/site-packages/treetaggerwrapper.py:2044: FutureWarning: Possible nested set at position 152\n",
      "  re.VERBOSE | re.IGNORECASE)\n",
      "/anaconda3/lib/python3.7/site-packages/treetaggerwrapper.py:2067: FutureWarning: Possible nested set at position 409\n",
      "  UrlMatch_re = re.compile(UrlMatch_expression, re.VERBOSE | re.IGNORECASE)\n",
      "/anaconda3/lib/python3.7/site-packages/treetaggerwrapper.py:2079: FutureWarning: Possible nested set at position 192\n",
      "  EmailMatch_re = re.compile(EmailMatch_expression, re.VERBOSE | re.IGNORECASE)\n"
     ]
    }
   ],
   "source": [
    "import treetaggerwrapper as ttpw\n",
    "tagger = ttpw.TreeTagger(TAGLANG='fr', TAGDIR='//Users/maymounasy/MAster2/installation/')\n",
    "# données d'apprentissage \n",
    "for i in range(len(x_train)):\n",
    "    tags = tagger.tag_text(x_train[i])\n",
    "    lemmas = [t.split('\\t')[-1] for t in tags]\n",
    "    x_train[i] = ' '.join(lemmas)\n",
    "\n",
    "# données de test\n",
    "for i in range(len(x_test)):\n",
    "    tags = tagger.tag_text(x_test[i])\n",
    "    lemmas = [t.split('\\t')[-1] for t in tags]\n",
    "    x_test[i] = ' '.join(lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Vectorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# données d'apprentissage \n",
    "tfidfconverter = TfidfVectorizer(max_features=1500, min_df=5, max_df=0.7)\n",
    "X_train = tfidfconverter.fit_transform(x_train).toarray()\n",
    "\n",
    "# données de test\n",
    "tfidfconverter = TfidfVectorizer(max_features=1500, min_df=5, max_df=0.7)\n",
    "X_test = tfidfconverter.fit_transform(x_test).toarray()\n",
    "#print(tfidfconverter.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. RandowForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "classifier.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
